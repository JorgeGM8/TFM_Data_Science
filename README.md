# AnÃ¡lisis del mercado inmobiliario y detecciÃ³n temprana de gentrificaciÃ³n en la ciudad de Madrid

Este proyecto aplica tÃ©cnicas de ciencia de datos para analizar la evoluciÃ³n del mercado inmobiliario madrileÃ±o entre 2011 y 2024, estimar la accesibilidad a la vivienda y detectar patrones de gentrificaciÃ³n a nivel distrital.


## ðŸ—’ï¸ DescripciÃ³n general

El estudio integra datos de Idealista, el Ayuntamiento de Madrid y el INE, generando mÃ¡s de 140.000 registros.

Se desarrollaron modelos predictivos de precios con LightGBM optimizados con Optuna, junto con el diseÃ±o de un Ãndice de Accesibilidad a la Vivienda (IAV) para medir desigualdades territoriales en compra y alquiler.

El anÃ¡lisis espacial y de clustering permitiÃ³ identificar zonas en proceso de transformaciÃ³n urbana, demostrando el potencial del aprendizaje automÃ¡tico para la planificaciÃ³n basada en evidencia.

Los resultados se integraron en una interfaz web con Streamlit.


## ðŸ‘¥ Autores
- Samantha Barone Guerra  
- Gaspar Campuzano Gallego  
- Jorge Galeano MatÃ©  
- Andrea Guerra Arguinzones

**Tutor:** Gabriel Valverde Castilla  
**Fecha:** octubre 2025  


## ðŸ“ Estructura del proyecto

```
â”œâ”€â”€ app                    # Interfaz web
â”‚   â””â”€â”€ .streamlit
â”œâ”€â”€ data                   # Datos (csv)
â”‚   â”œâ”€â”€ final
â”‚   â”œâ”€â”€ processed
â”‚   â”œâ”€â”€ raw
â”‚   â””â”€â”€ webscraping
â”‚       â”œâ”€â”€ cached_pages
â”‚       â””â”€â”€ csv
â”œâ”€â”€ models                 # Modelos y encoders
â”œâ”€â”€ notebooks              # Notebooks
â”œâ”€â”€ reports                # Reportes bÃ¡sicos y grÃ¡ficas
â”‚   â””â”€â”€ figures
â”œâ”€â”€ src                    # Scripts de Python
â”‚   â””â”€â”€ webscraping
â”œâ”€â”€ utils                  # Funciones definidas
â””â”€â”€ (archivos)
```

## âš™ï¸ MetodologÃ­a

1. **RecolecciÃ³n de datos**
   - Web scraping automatizado de Idealista (Python, `requests`, `BeautifulSoup`, `selenium`).
   - Datos oficiales (renta, poblaciÃ³n, paro, zonas verdes, etc.).

2. **Preprocesamiento**
   - Limpieza, normalizaciÃ³n y enriquecimiento de variables.
   - ReconstrucciÃ³n temporal 2011â€“2024 mediante proyecciÃ³n proporcional distrital.

3. **Modelado predictivo**
   - Entrenamiento con algoritmos de regresiÃ³n supervisada: Ridge, KNN, MLP, HistGradientBoosting, LightGBM.
   - ValidaciÃ³n temporal con `TimeSeriesSplit` y optimizaciÃ³n de hiperparÃ¡metros mediante Optuna.

4. **Ãndice de Accesibilidad (IAV)**
   - CÃ¡lculo de IAV de compra y de alquiler, basados en precios (â‚¬/mÂ²), superficie mÃ­nima y renta media disponible.
   - RepresentaciÃ³n de desigualdades territoriales en el acceso a la vivienda.

5. **AnÃ¡lisis de gentrificaciÃ³n**
   - CreaciÃ³n de embeddings residenciales y agrupamiento mediante UMAP y KMeans.
   - IdentificaciÃ³n de patrones de transformaciÃ³n socioespacial y gradientes de gentrificaciÃ³n.

6. **Interfaz interactiva**
   - AplicaciÃ³n desarrollada en Streamlit para la visualizaciÃ³n, predicciÃ³n y anÃ¡lisis de los resultados de forma dinÃ¡mica.


## *ï¸âƒ£ TecnologÃ­as utilizadas

- Python >=3.12
- Pandas, NumPy, Scikit-learn, PyTorch, LightGBM, Optuna
- Matplotlib, Seaborn, Plotly
- Streamlit
- UMAP, KMeans
- BeautifulSoup, Selenium


## âš¡ EjecuciÃ³n

Para ejecutar los archivos, se debe crear un entorno virtual. Para ello, hay tres opciones: con UV, con pip y con conda. Los tres son igual de vÃ¡lidos.

```bash
# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate   # o venv\Scripts\activate en Windows

# Instalar dependencias con UV (opcional)
uv init
uv sync

# Instalar dependencias con pip
pip install .   # Uso de pyproject.toml (recomendado)
pip install -r requirements.txt   # O uso de archivo de requirements

# Instalar dependencias con conda
conda install --file requirements.txt

# Ejecutar la interfaz web
streamlit run app/app.py
```


## âœ… Licencia y uso
Uso exclusivamente acadÃ©mico.

Los datos obtenidos mediante scraping se procesan de forma anÃ³nima y agregada, respetando las polÃ­ticas del portal Idealista.

---
---

# Real estate market analysis and early detection of gentrification in the city of Madrid

This project applies data science techniques to analyze the evolution of the Madrid real estate market between 2011 and 2024, estimate housing accessibility, and detect gentrification patterns at the district level.


## ðŸ—’ï¸ Overview

The study integrates data from Idealista, the Madrid City Council, and the INE, generating over 140,000 records.

Predictive price models were developed using LightGBM optimized with Optuna, along with the design of a Housing Accessibility Index (HAI) to measure territorial inequalities in buying and renting.

Spatial and clustering analysis allowed the identification of areas undergoing urban transformation, demonstrating the potential of machine learning for evidence-based planning.

The results were integrated into a web interface using Streamlit.


## ðŸ‘¥ Authors

- Samantha Barone Guerra  
- Gaspar Campuzano Gallego  
- Jorge Galeano MatÃ©  
- Andrea Guerra Arguinzones  

**Advisor:** Gabriel Valverde Castilla  
**Date:** October 2025


## ðŸ“ Project Structure

```
â”œâ”€â”€ app                    # Web interface
â”‚   â””â”€â”€ .streamlit
â”œâ”€â”€ data                   # Data (csv)
â”‚   â”œâ”€â”€ final
â”‚   â”œâ”€â”€ processed
â”‚   â”œâ”€â”€ raw
â”‚   â””â”€â”€ webscraping
â”‚       â”œâ”€â”€ cached_pages
â”‚       â””â”€â”€ csv
â”œâ”€â”€ models                 # Models and encoders
â”œâ”€â”€ notebooks              # Notebooks
â”œâ”€â”€ reports                # Basic reports and plots
â”‚   â””â”€â”€ figures
â”œâ”€â”€ src                    # Python scripts
â”‚   â””â”€â”€ webscraping
â”œâ”€â”€ utils                  # Defined functions
â””â”€â”€ (files)
```


## âš™ï¸ Methodology

1. **Data collection**
   - Automated web scraping from Idealista (Python, requests, BeautifulSoup, Selenium).
   - Official data (income, population, unemployment, green areas, etc.).
2. **Preprocessing**
   - Cleaning, normalization, and variable enrichment.
   - Temporal reconstruction 2011â€“2024 through proportional district projection.
3. **Predictive modeling**
   - Training with supervised regression algorithms: Ridge, KNN, MLP, HistGradientBoosting, LightGBM.
   - Temporal validation with TimeSeriesSplit and hyperparameter optimization using Optuna.
4. **Accessibility Index (HAI)**
   - Calculation of purchase and rental HAI based on prices (â‚¬/mÂ²), minimum surface, and average available income.
   - Representation of territorial inequalities in housing access.
5. **Gentrification analysis**
   - Creation of residential embeddings and clustering using UMAP and KMeans.
   - Identification of socio-spatial transformation patterns and gentrification gradients.
6. **Interactive interface**
   - Application developed in Streamlit for dynamic visualization, prediction, and analysis of results.


## *ï¸âƒ£ Technologies used

- Python >=3.12
- Pandas, NumPy, Scikit-learn, PyTorch, LightGBM, Optuna
- Matplotlib, Seaborn, Plotly
- Streamlit
- UMAP, KMeans
- BeautifulSoup, Selenium


## âš¡ Execution

To run the files, a virtual environment must be created. There are three options: with UV, with pip, and with conda. All three are equally valid.

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate   # or venv\Scripts\activate on Windows

# Install dependencies with UV (optional)
uv init
uv sync

# Install dependencies with pip
pip install .   # Using pyproject.toml (recommended)
pip install -r requirements.txt   # Or using a requirements file

# Install dependencies with conda
conda install --file requirements.txt

# Run the web interface
streamlit run app/app.py
```


## âœ… License and Use

For academic use only.

Data obtained through scraping is processed anonymously and in aggregate, respecting Idealistaâ€™s portal policies.