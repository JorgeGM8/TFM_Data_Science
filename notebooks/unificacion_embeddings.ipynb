{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e1cc6e",
   "metadata": {},
   "source": [
    "UNIFICACION ALQUILER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a0f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Listo.\n",
      "Archivos guardados:\n",
      " - C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\Alquiler\\alquiler_unificado.csv \n",
      " - C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\Alquiler\\alquiler_unificado.parquet\n",
      "Filas: 6347 | Columnas: 11\n",
      "Distritos detectados: ['arganzuela', 'barajas', 'barrio-de-salamanca', 'carabanchel', 'centro', 'chamartin', 'chamberi', 'ciudad-lineal', 'fuencarral', 'hortaleza'] ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Ruta alquiler\n",
    "DATA_DIR = Path(r\"C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\Alquiler\")\n",
    "\n",
    "\n",
    "def read_csv_safely(p: Path) -> pd.DataFrame:\n",
    "\n",
    "    for enc in (\"utf-8\", \"latin-1\"):\n",
    "        try:\n",
    "            return pd.read_csv(p, encoding=enc)\n",
    "        except Exception:\n",
    "            pass\n",
    "    for enc in (\"utf-8\", \"latin-1\"):\n",
    "        try:\n",
    "            return pd.read_csv(p, encoding=enc, sep=\";\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise RuntimeError(f\"No pude leer {p}\")\n",
    "\n",
    "def parse_distrito_from_filename(p: Path) -> str:\n",
    "    \n",
    "    name = p.stem.lower()\n",
    "    m = re.search(r\"distrito_([a-z\\-√±]+)_alquiler\", name)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    cols_map = {\n",
    "        \"precio\":\"precio\",\n",
    "        \"localidad\":\"localidad\",\n",
    "        \"tama√±o\":\"tamanio\",\n",
    "        \"tamano\":\"tamanio\",\n",
    "        \"tamanio\":\"tamanio\",\n",
    "        \"habitaciones\":\"habitaciones\",\n",
    "        \"descripcion\":\"descripcion\",\n",
    "        \"link\":\"link\",\n",
    "        \"descripcion_larga\":\"descripcion_larga\",\n",
    "        \"distrito\":\"distrito\",\n",
    "    }\n",
    "    expected = [\"precio\",\"localidad\",\"tamanio\",\"habitaciones\",\"descripcion\",\"link\",\"descripcion_larga\",\"distrito\"]\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    df = df.rename(columns={c: cols_map.get(c, c) for c in df.columns})\n",
    "    for c in expected:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    return df[expected]\n",
    "\n",
    "def std_text(s: str) -> str:\n",
    "    \n",
    "    if pd.isna(s): return s\n",
    "    s = str(s).lower().strip()\n",
    "    s = ''.join(\n",
    "        ch for ch in unicodedata.normalize('NFKD', s)\n",
    "        if not unicodedata.combining(ch)\n",
    "    )\n",
    "    s = s.replace(\"-\", \"\").replace(\" \", \"\")\n",
    "    return s\n",
    "\n",
    "# Recorrer archivos y unir\n",
    "files = sorted(DATA_DIR.glob(\"*.csv\"))\n",
    "frames = []\n",
    "\n",
    "for p in files:\n",
    "    df = read_csv_safely(p)\n",
    "    df = normalize_columns(df)\n",
    "\n",
    "    # Completar distrito desde el nombre si no viene dentro del CSV\n",
    "    distrito_name = parse_distrito_from_filename(p)\n",
    "    if df[\"distrito\"].isna().all() or (df[\"distrito\"].astype(str).str.strip() == \"\").all():\n",
    "        df[\"distrito\"] = distrito_name\n",
    "    else:\n",
    "        \n",
    "        df[\"distrito\"] = df[\"distrito\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "    \n",
    "    df[\"operacion\"] = \"alquiler\"\n",
    "    df[\"origen_archivo\"] = p.name\n",
    "    \n",
    "    df[\"distrito_std\"] = df[\"distrito\"].apply(std_text)\n",
    "\n",
    "    frames.append(df)\n",
    "\n",
    "df_alq = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "if \"link\" in df_alq.columns:\n",
    "    df_alq = df_alq.drop_duplicates(subset=[\"link\",\"operacion\"], keep=\"first\")\n",
    "\n",
    "# Guardar resultados\n",
    "out_csv = DATA_DIR / \"alquiler_unificado.csv\"\n",
    "out_parquet = DATA_DIR / \"alquiler_unificado.parquet\"\n",
    "\n",
    "df_alq.to_csv(out_csv, index=False)\n",
    "try:\n",
    "    df_alq.to_parquet(out_parquet, index=False)\n",
    "except Exception:\n",
    "    pass  \n",
    "\n",
    "\n",
    "print(\"Archivos guardados:\\n -\", out_csv, \"\\n -\", out_parquet if out_parquet.exists() else \"(parquet omitido)\")\n",
    "print(\"Filas:\", len(df_alq), \"| Columnas:\", len(df_alq.columns))\n",
    "print(\"Distritos detectados:\", sorted(df_alq['distrito'].dropna().unique().tolist())[:10], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde6556",
   "metadata": {},
   "source": [
    "UNIFICACION VENTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f83a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Listo\n",
      "Guardado: C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\Venta\\venta_unificado.csv | filas: 9613 columnas: 11\n",
      "Ejemplo de distritos: ['arganzuela', 'barajas', 'barrio-de-salamanca', 'carabanchel', 'centro', 'chamartin', 'chamberi', 'ciudad-lineal', 'fuencarral', 'hortaleza'] ‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Ruta venta\n",
    "DATA_DIR = Path(r\"C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\Venta\")\n",
    "\n",
    "\n",
    "def read_csv_safely(p: Path) -> pd.DataFrame:\n",
    "    for enc in (\"utf-8\", \"latin-1\"):\n",
    "        try:\n",
    "            return pd.read_csv(p, encoding=enc)\n",
    "        except Exception:\n",
    "            pass\n",
    "    for enc in (\"utf-8\", \"latin-1\"):\n",
    "        try:\n",
    "            return pd.read_csv(p, encoding=enc, sep=\";\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise RuntimeError(f\"No pude leer {p}\")\n",
    "\n",
    "def parse_distrito_from_filename(p: Path) -> str:\n",
    "    \n",
    "    name = p.stem.lower()\n",
    "    m = re.search(r\"distrito_([a-z\\-√±]+)_venta\", name)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols_map = {\n",
    "        \"precio\":\"precio\",\n",
    "        \"localidad\":\"localidad\",\n",
    "        \"tama√±o\":\"tamanio\",\n",
    "        \"tamano\":\"tamanio\",\n",
    "        \"tamanio\":\"tamanio\",\n",
    "        \"habitaciones\":\"habitaciones\",\n",
    "        \"descripcion\":\"descripcion\",\n",
    "        \"link\":\"link\",\n",
    "        \"descripcion_larga\":\"descripcion_larga\",\n",
    "        \"distrito\":\"distrito\",\n",
    "    }\n",
    "    expected = [\"precio\",\"localidad\",\"tamanio\",\"habitaciones\",\"descripcion\",\"link\",\"descripcion_larga\",\"distrito\"]\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    df = df.rename(columns={c: cols_map.get(c, c) for c in df.columns})\n",
    "    for c in expected:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    return df[expected]\n",
    "\n",
    "def std_text(s: str) -> str:\n",
    "    if pd.isna(s): return s\n",
    "    s = str(s).lower().strip()\n",
    "    s = ''.join(ch for ch in unicodedata.normalize('NFKD', s) if not unicodedata.combining(ch))\n",
    "    return s.replace(\"-\", \"\").replace(\" \", \"\")\n",
    "\n",
    "# Unificaci√≥n\n",
    "files = sorted(DATA_DIR.glob(\"*.csv\"))\n",
    "frames = []\n",
    "\n",
    "for p in files:\n",
    "    df = read_csv_safely(p)\n",
    "    df = normalize_columns(df)\n",
    "\n",
    "    distrito_name = parse_distrito_from_filename(p)\n",
    "    if df[\"distrito\"].isna().all() or (df[\"distrito\"].astype(str).str.strip() == \"\").all():\n",
    "        df[\"distrito\"] = distrito_name\n",
    "    else:\n",
    "        df[\"distrito\"] = df[\"distrito\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "    df[\"operacion\"] = \"venta\"\n",
    "    df[\"origen_archivo\"] = p.name\n",
    "    df[\"distrito_std\"] = df[\"distrito\"].apply(std_text)\n",
    "\n",
    "    frames.append(df)\n",
    "\n",
    "df_venta = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "if \"link\" in df_venta.columns:\n",
    "    df_venta = df_venta.drop_duplicates(subset=[\"link\",\"operacion\"], keep=\"first\")\n",
    "\n",
    "# Guardar\n",
    "out_csv = DATA_DIR / \"venta_unificado.csv\"\n",
    "out_parquet = DATA_DIR / \"venta_unificado.parquet\"\n",
    "\n",
    "df_venta.to_csv(out_csv, index=False)\n",
    "try:\n",
    "    df_venta.to_parquet(out_parquet, index=False) \n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"Guardado:\", out_csv, \"| filas:\", len(df_venta), \"columnas:\", len(df_venta.columns))\n",
    "print(\"Ejemplo de distritos:\", sorted(df_venta['distrito'].dropna().unique().tolist())[:10], \"‚Ä¶\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b191a",
   "metadata": {},
   "source": [
    "UNIFICACION TOTAL DE CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Unificaci√≥n completa\n",
      "Archivo: C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\inmuebles_unificado_total.csv | Filas: 15960 | Columnas: 11\n",
      "Operaciones: {'venta': 9613, 'alquiler': 6347}\n",
      "Ejemplo columnas: ['descripcion', 'descripcion_larga', 'distrito', 'distrito_std', 'habitaciones', 'link', 'localidad', 'operacion', 'origen_archivo', 'precio', 'tamanio'] ‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Rutas de datasets\n",
    "BASE_DIR = Path(r\"C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\")\n",
    "f_alq = BASE_DIR / \"Alquiler\" / \"alquiler_unificado.csv\"\n",
    "f_vta = BASE_DIR / \"Venta\" / \"venta_unificado.csv\"\n",
    "\n",
    "\n",
    "alq = pd.read_csv(f_alq)\n",
    "vta = pd.read_csv(f_vta)\n",
    "\n",
    "# Alinear columnas\n",
    "all_cols = sorted(set(alq.columns) | set(vta.columns))\n",
    "for df in (alq, vta):\n",
    "    for c in all_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    df = df[all_cols]\n",
    "\n",
    "# Unir\n",
    "df_all = pd.concat([alq[all_cols], vta[all_cols]], ignore_index=True)\n",
    "\n",
    "\n",
    "if {\"link\",\"operacion\"}.issubset(df_all.columns):\n",
    "    df_all = df_all.drop_duplicates(subset=[\"link\",\"operacion\"], keep=\"first\")\n",
    "\n",
    "#Guardar resultado\n",
    "out_csv = BASE_DIR / \"inmuebles_unificado_total.csv\"\n",
    "out_parquet = BASE_DIR / \"inmuebles_unificado_total.parquet\"\n",
    "\n",
    "df_all.to_csv(out_csv, index=False)\n",
    "try:\n",
    "    df_all.to_parquet(out_parquet, index=False)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"Archivo:\", out_csv, \"| Filas:\", len(df_all), \"| Columnas:\", len(df_all.columns))\n",
    "print(\"Operaciones:\", df_all[\"operacion\"].value_counts(dropna=False).to_dict())\n",
    "print(\"Ejemplo columnas:\", df_all.columns.tolist()[:12], \"‚Ä¶\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59111db",
   "metadata": {},
   "source": [
    "CREAR LOS EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6acdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.56.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce37112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tf-keras in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (2.20.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.32.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471eb362",
   "metadata": {},
   "source": [
    "EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167170df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andre\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Embeddings generados y guardados en: C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Archivo de entrada/salida\n",
    "INPUT_FILE = Path(r\"C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\inmuebles_unificado_total.csv\")\n",
    "OUTPUT_BASENAME = INPUT_FILE.with_suffix('').name  \n",
    "\n",
    "# Cargar \n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "\n",
    "def std_text(s: str) -> str:\n",
    "    if pd.isna(s): return s\n",
    "    s = str(s).lower().strip()\n",
    "    s = ''.join(ch for ch in unicodedata.normalize('NFKD', s) if not unicodedata.combining(ch))\n",
    "    return s\n",
    "\n",
    "\n",
    "KEYWORDS = [\"antig√ºedad\", \"ba√±os\", \"garaje\", \"trastero\", \"piscina\", \"terraza\"]\n",
    "for kw in KEYWORDS:\n",
    "    col = f\"has_{kw}\".replace(\"√±\", \"n\")  # ej: has_banos\n",
    "    df[col] = df[\"descripcion_larga\"].fillna(\"\").str.lower().apply(lambda x: 1 if kw in x else 0)\n",
    "\n",
    "\n",
    "def precio_to_float(s):\n",
    "    if pd.isna(s): return pd.NA\n",
    "    s = str(s).replace(\".\", \"\").replace(\"‚Ç¨\",\"\").replace(\" \", \"\").replace(\",\", \".\")\n",
    "    try: return float(s)\n",
    "    except: return pd.NA\n",
    "df[\"precio_num\"] = df[\"precio\"].apply(precio_to_float)\n",
    "\n",
    "\n",
    "df[\"distrito_std\"] = df[\"distrito\"].astype(str).map(std_text).str.replace(\"-\", \"\").str.replace(\" \", \"\")\n",
    "\n",
    "# Extracciones num√©ricas (ba√±os, a√±o construcci√≥n, antig√ºedad)\n",
    "MAPA_NUM = {\"un\":1,\"una\":1,\"uno\":1,\"dos\":2,\"tres\":3,\"cuatro\":4,\"cinco\":5,\"seis\":6,\"siete\":7,\"ocho\":8,\"nueve\":9,\"diez\":10}\n",
    "CURRENT_YEAR = datetime.now().year\n",
    "\n",
    "def extract_num_banos(texto: str):\n",
    "    if pd.isna(texto): return None\n",
    "    t = texto.lower()\n",
    "    m = re.search(r'(\\d+)\\s*ba√±', t)\n",
    "    if m: return int(m.group(1))\n",
    "    for palabra, val in MAPA_NUM.items():\n",
    "        if re.search(rf'\\b{palabra}\\s+ba√±', t): return val\n",
    "    return None\n",
    "\n",
    "def extract_year_built(texto: str):\n",
    "    if pd.isna(texto): return None\n",
    "    t = texto.lower()\n",
    "    patrones = [\n",
    "        r'construid[oa]\\s+en\\s+(19\\d{2}|20\\d{2})',\n",
    "        r'a√±o\\s*(de)?\\s*construcci[o√≥]n[:\\s]+(19\\d{2}|20\\d{2})',\n",
    "        r'del?\\s+a√±o\\s+(19\\d{2}|20\\d{2})',\n",
    "        r'en\\s+(19\\d{2}|20\\d{2})\\s+se\\s+construy[o√≥]',\n",
    "        r'obra\\s+del?\\s+(19\\d{2}|20\\d{2})',\n",
    "        r'edificio\\s+(del?\\s+)?(19\\d{2}|20\\d{2})'\n",
    "    ]\n",
    "    for pat in patrones:\n",
    "        m = re.search(pat, t)\n",
    "        if m:\n",
    "            y = int(m.groups()[-1])\n",
    "            if 1900 <= y <= CURRENT_YEAR: return y\n",
    "    m = re.search(r'\\b(19\\d{2}|20\\d{2})\\b', t)\n",
    "    if m:\n",
    "        y = int(m.group(1))\n",
    "        if 1900 <= y <= CURRENT_YEAR: return y\n",
    "    return None\n",
    "\n",
    "def extract_antiguedad(texto: str):\n",
    "    if pd.isna(texto): return None\n",
    "    t = texto.lower()\n",
    "    if re.search(r'\\b(obra\\s+nueva|a\\s+estrenar)\\b', t): return 0\n",
    "    m = re.search(r'(\\d+)\\s*a√±os?\\s*(de\\s*)?antig(√º|u)edad', t)\n",
    "    if m: return int(m.group(1))\n",
    "    for palabra, val in MAPA_NUM.items():\n",
    "        if re.search(rf'{palabra}\\s+a√±os?\\s*(de\\s*)?antig(√º|u)edad', t): return val\n",
    "    return None\n",
    "\n",
    "df[\"num_banos\"] = df[\"descripcion_larga\"].apply(extract_num_banos)\n",
    "df[\"anio_construccion\"] = df[\"descripcion_larga\"].apply(extract_year_built)\n",
    "df[\"antiguedad_texto\"] = df[\"descripcion_larga\"].apply(extract_antiguedad)\n",
    "df[\"antiguedad_calc\"] = df[\"anio_construccion\"].apply(lambda y: CURRENT_YEAR - y if pd.notna(y) else None)\n",
    "df[\"antiguedad_final\"] = df[\"antiguedad_texto\"].fillna(df[\"antiguedad_calc\"])\n",
    "\n",
    "# Texto para el embedding\n",
    "def build_embedding_text(row):\n",
    "    partes = [\n",
    "        f\"operacion: {row.get('operacion','')}\",\n",
    "        f\"distrito: {row.get('distrito','')}\",\n",
    "        f\"tamanio_m2: {row.get('tamanio','')}\",\n",
    "        f\"habitaciones: {row.get('habitaciones','')}\",\n",
    "        f\"banos: {row.get('num_banos','')}\",\n",
    "        f\"garaje: {row.get('has_garaje',0)}\",\n",
    "        f\"trastero: {row.get('has_trastero',0)}\",\n",
    "        f\"piscina: {row.get('has_piscina',0)}\",\n",
    "        f\"terraza: {row.get('has_terraza',0)}\",\n",
    "        f\"antiguedad: {row.get('antiguedad_final','')}\",\n",
    "        f\"descripcion: {str(row.get('descripcion_larga',''))[:1200]}\",\n",
    "    ]\n",
    "    return \" | \".join(map(lambda s: str(s), partes))\n",
    "\n",
    "df[\"texto_embedding\"] = df.apply(build_embedding_text, axis=1)\n",
    "\n",
    "# Generar embeddings \n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # r√°pido y s√≥lido\n",
    "df[\"embedding\"] = df[\"texto_embedding\"].fillna(\"\").apply(lambda x: model.encode(x))\n",
    "\n",
    "\n",
    "cols = [c for c in df.columns if c != \"embedding\"] + [\"embedding\"]\n",
    "df = df[cols]\n",
    "\n",
    "OUT_DIR = INPUT_FILE.parent\n",
    "df.to_pickle(OUT_DIR / f\"{OUTPUT_BASENAME}_with_embeddings.pkl\")\n",
    "\n",
    "# CSV \n",
    "df_csv = df.copy()\n",
    "df_csv[\"embedding_str\"] = df_csv[\"embedding\"].apply(lambda v: \",\".join(map(str, v)))\n",
    "df_csv = df_csv.drop(columns=[\"embedding\"])\n",
    "df_csv.to_csv(OUT_DIR / f\"{OUTPUT_BASENAME}_with_embeddings.csv\", index=False)\n",
    "\n",
    "# Parquet \n",
    "try:\n",
    "    df.to_parquet(OUT_DIR / f\"{OUTPUT_BASENAME}_with_embeddings.parquet\", index=False)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Embeddings generados y guardados en:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855dd112",
   "metadata": {},
   "source": [
    "VERIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b259181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       descripcion  \\\n",
      "0  Planta 3¬™ exterior con ascensor   \n",
      "1  Planta 3¬™ exterior con ascensor   \n",
      "2  Planta 6¬™ exterior con ascensor   \n",
      "\n",
      "                                   descripcion_larga    distrito distrito_std  \\\n",
      "0  \\nDISPONIBLE A PARTIR 1 DE DICIEMBRE 2025\\nAla...  arganzuela   arganzuela   \n",
      "1  \\nDISPONIBLE EN OCTUBRE! MODUS HOME PONE A TU ...  arganzuela   arganzuela   \n",
      "2  \\nPrecioso apartamento, reformado √≠ntegramente...  arganzuela   arganzuela   \n",
      "\n",
      "   habitaciones                  link  \\\n",
      "0             1  /inmueble/109262818/   \n",
      "1             2  /inmueble/109227606/   \n",
      "2             1   /inmueble/25140719/   \n",
      "\n",
      "                                           localidad operacion  \\\n",
      "0             Piso en Calle de Ricardo Damas Legazpi  alquiler   \n",
      "1  D√∫plex en Calle de Bernardino Obreg√≥n Palos de...  alquiler   \n",
      "2                   Piso en Paseo de las Delicias 13  alquiler   \n",
      "\n",
      "           origen_archivo precio  ... has_piscina  has_terraza  precio_num  \\\n",
      "0  alquiler_unificado.csv   1.28  ...           0            0       128.0   \n",
      "1  alquiler_unificado.csv    1.7  ...           0            1        17.0   \n",
      "2  alquiler_unificado.csv    1.3  ...           0            0        13.0   \n",
      "\n",
      "   num_banos  anio_construccion  antiguedad_texto  antiguedad_calc  \\\n",
      "0        NaN             2025.0               NaN              0.0   \n",
      "1        2.0                NaN               NaN              NaN   \n",
      "2        NaN                NaN               NaN              NaN   \n",
      "\n",
      "   antiguedad_final                                    texto_embedding  \\\n",
      "0               0.0  operacion: alquiler | distrito: arganzuela | t...   \n",
      "1               NaN  operacion: alquiler | distrito: arganzuela | t...   \n",
      "2               NaN  operacion: alquiler | distrito: arganzuela | t...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [0.07376748, 0.01204776, 0.0029773542, -0.0410...  \n",
      "1  [0.006745178, 0.021173792, -0.036151364, -0.07...  \n",
      "2  [0.03334184, 0.0030579446, -0.0073190397, -0.0...  \n",
      "\n",
      "[3 rows x 25 columns]\n",
      "\n",
      "Columnas: ['descripcion', 'descripcion_larga', 'distrito', 'distrito_std', 'habitaciones', 'link', 'localidad', 'operacion', 'origen_archivo', 'precio', 'tamanio', 'has_antig√ºedad', 'has_banos', 'has_garaje', 'has_trastero', 'has_piscina', 'has_terraza', 'precio_num', 'num_banos', 'anio_construccion', 'antiguedad_texto', 'antiguedad_calc', 'antiguedad_final', 'texto_embedding', 'embedding']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pkl = pd.read_pickle(r\"C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\inmuebles_unificado_total_with_embeddings.pkl\"\n",
    ")\n",
    "print(df_pkl.head(3))\n",
    "print(\"\\nColumnas:\", df_pkl.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94109e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 15960 | Columnas: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Filas:\", df_pkl.shape[0], \"| Columnas:\", df_pkl.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e28e5068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Longitud embedding: 384\n",
      "Primeros 10 valores: [ 0.07376748  0.01204776  0.00297735 -0.04105594 -0.10310872 -0.00557283\n",
      "  0.04342492 -0.01798573 -0.08226091 -0.0104314 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(df_pkl[\"embedding\"].iloc[0]))\n",
    "print(\"Longitud embedding:\", len(df_pkl[\"embedding\"].iloc[0]))\n",
    "print(\"Primeros 10 valores:\", df_pkl[\"embedding\"].iloc[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28c2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  precio  precio_num  num_banos  anio_construccion  antiguedad_final  \\\n",
      "0   1.28       128.0        NaN             2025.0               0.0   \n",
      "1    1.7        17.0        2.0                NaN               NaN   \n",
      "2    1.3        13.0        NaN                NaN               NaN   \n",
      "3    1.5        15.0        NaN                NaN               NaN   \n",
      "4    1.0        10.0        1.0                NaN               NaN   \n",
      "5    1.8        18.0        NaN                NaN               NaN   \n",
      "6    1.3        13.0        NaN                NaN               NaN   \n",
      "7   1.35       135.0        NaN                NaN               NaN   \n",
      "8    1.6        16.0        NaN                NaN               NaN   \n",
      "9  1.423      1423.0        NaN                NaN               NaN   \n",
      "\n",
      "   has_garaje  has_piscina  has_terraza  \n",
      "0           0            0            0  \n",
      "1           0            0            1  \n",
      "2           0            0            0  \n",
      "3           0            0            0  \n",
      "4           1            0            0  \n",
      "5           0            0            0  \n",
      "6           1            0            0  \n",
      "7           0            0            0  \n",
      "8           0            0            0  \n",
      "9           0            0            0  \n"
     ]
    }
   ],
   "source": [
    "print(df_pkl[[\n",
    "    \"precio\", \"precio_num\", \"num_banos\", \n",
    "    \"anio_construccion\", \"antiguedad_final\", \n",
    "    \"has_garaje\", \"has_piscina\", \"has_terraza\"\n",
    "]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cbedaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operaciones disponibles: ['alquiler' 'venta']\n",
      "Distritos: ['arganzuela' 'barajas' 'barrio-de-salamanca' 'carabanchel' 'centro'\n",
      " 'chamartin' 'chamberi' 'ciudad-lineal' 'fuencarral' 'hortaleza' 'latina'\n",
      " 'moncloa' 'moratalaz' 'puente-de-vallecas' 'retiro' 'san-blas' 'tetuan'\n",
      " 'usera' 'vicalvaro' 'villa-de-vallecas' 'villaverde']\n"
     ]
    }
   ],
   "source": [
    "print(\"Operaciones disponibles:\", df_pkl[\"operacion\"].unique())\n",
    "print(\"Distritos:\", df_pkl[\"distrito\"].unique()[:21])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af16ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['descripcion', 'descripcion_larga', 'distrito', 'distrito_std', 'habitaciones', 'link', 'localidad', 'operacion', 'origen_archivo', 'precio', 'tamanio', 'has_antig√ºedad', 'has_banos', 'has_garaje', 'has_trastero', 'has_piscina', 'has_terraza', 'precio_num', 'num_banos', 'anio_construccion', 'antiguedad_texto', 'antiguedad_calc', 'antiguedad_final', 'texto_embedding', 'embedding']\n"
     ]
    }
   ],
   "source": [
    "print(df_pkl.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c1959b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['descripcion', 'descripcion_larga', 'distrito', 'distrito_std',\n",
      "       'habitaciones', 'link', 'localidad', 'operacion', 'origen_archivo',\n",
      "       'precio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_pkl.columns[:10])   # primeras 10 columnas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f91fe",
   "metadata": {},
   "source": [
    "CORRECCION DE LA COLUMNA PRECIO_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17b329a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_precio(s):\n",
    "    if pd.isna(s): \n",
    "        return pd.NA\n",
    "    s = str(s).replace(\"‚Ç¨\",\"\").replace(\" \", \"\")\n",
    "    \n",
    "    # Caso con punto decimal y pocos d√≠gitos \n",
    "    if re.match(r'^\\d+(\\.\\d+)?$', s):\n",
    "        valor = float(s)\n",
    "        return round(valor * 1000)  \n",
    "    \n",
    "    # Caso con miles separadores \n",
    "    s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "df[\"precio_num\"] = df[\"precio\"].apply(corregir_precio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45385ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precio  precio_num\n",
      "0    1.28      1280.0\n",
      "1     1.7      1700.0\n",
      "2     1.3      1300.0\n",
      "3     1.5      1500.0\n",
      "4     1.0      1000.0\n",
      "5     1.8      1800.0\n",
      "6     1.3      1300.0\n",
      "7    1.35      1350.0\n",
      "8     1.6      1600.0\n",
      "9   1.423      1423.0\n",
      "10    1.8      1800.0\n",
      "11    1.6      1600.0\n",
      "12    2.3      2300.0\n",
      "13    2.0      2000.0\n",
      "14    1.7      1700.0\n",
      "15    1.5      1500.0\n",
      "16   1.39      1390.0\n",
      "17  1.499      1499.0\n",
      "18    1.2      1200.0\n",
      "19  1.636      1636.0\n",
      "\n",
      "Estad√≠sticas precio_num:\n",
      "count    1.596000e+04\n",
      "mean     5.502592e+05\n",
      "std      1.015089e+06\n",
      "min      1.000000e+03\n",
      "25%      2.300000e+03\n",
      "50%      2.515355e+05\n",
      "75%      6.705000e+05\n",
      "max      1.500000e+07\n",
      "Name: precio_num, dtype: float64\n",
      "\n",
      "Posibles errores (precio_num < 10000):\n",
      "   precio  precio_num\n",
      "0    1.28      1280.0\n",
      "1     1.7      1700.0\n",
      "2     1.3      1300.0\n",
      "3     1.5      1500.0\n",
      "4     1.0      1000.0\n",
      "5     1.8      1800.0\n",
      "6     1.3      1300.0\n",
      "7    1.35      1350.0\n",
      "8     1.6      1600.0\n",
      "9   1.423      1423.0\n",
      "10    1.8      1800.0\n",
      "11    1.6      1600.0\n",
      "12    2.3      2300.0\n",
      "13    2.0      2000.0\n",
      "14    1.7      1700.0\n"
     ]
    }
   ],
   "source": [
    "# Mostrar ejemplos de la conversi√≥n\n",
    "print(df[[\"precio\", \"precio_num\"]].head(20))\n",
    "\n",
    "# Revisar valores m√≠nimos y m√°ximos\n",
    "print(\"\\nEstad√≠sticas precio_num:\")\n",
    "print(df[\"precio_num\"].describe())\n",
    "\n",
    "# Buscar precios peque√±os sospechosos (ej: < 10,000 ‚Ç¨)\n",
    "print(\"\\nPosibles errores (precio_num < 10000):\")\n",
    "print(df.loc[df[\"precio_num\"] < 10000, [\"precio\", \"precio_num\"]].head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e03d6f",
   "metadata": {},
   "source": [
    "GUARDAR ARCHIVOS FINALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivos guardados:\n",
      " - CSV: C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\inmuebles_unificado_total_final.csv\n",
      " - PKL: C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\inmuebles_unificado_total_final.pkl\n",
      " - Parquet: C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\inmuebles_unificado_total_final.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Carpeta de salida \n",
    "OUT_DIR = Path(r\"C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\")\n",
    "\n",
    "# Nombres de salida\n",
    "out_csv = OUT_DIR / \"inmuebles_unificado_total_final.csv\"\n",
    "out_parquet = OUT_DIR / \"inmuebles_unificado_total_final.parquet\"\n",
    "out_pkl = OUT_DIR / \"inmuebles_unificado_total_final.pkl\"\n",
    "\n",
    "#Guardar en CSV \n",
    "df_csv = df.copy()\n",
    "if \"embedding\" in df_csv.columns:\n",
    "    df_csv[\"embedding_str\"] = df_csv[\"embedding\"].apply(lambda v: \",\".join(map(str, v)))\n",
    "    df_csv = df_csv.drop(columns=[\"embedding\"])\n",
    "df_csv.to_csv(out_csv, index=False)\n",
    "\n",
    "# Guardar en Parquet \n",
    "try:\n",
    "    df.to_parquet(out_parquet, index=False)\n",
    "except Exception as e:\n",
    "    print(\"No se pudo guardar en Parquet:\", e)\n",
    "\n",
    "# Guardar en PKL \n",
    "df.to_pickle(out_pkl)\n",
    "\n",
    "\n",
    "print(\" - CSV:\", out_csv)\n",
    "print(\" - PKL:\", out_pkl)\n",
    "print(\" - Parquet:\", out_parquet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601721b2",
   "metadata": {},
   "source": [
    "ANALISIS INICIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo final \n",
    "df = pd.read_pickle(r\"C:\\Users\\andre\\OneDrive\\Documentos\\IMF\\TFM\\Nuevos CSV\\descargas\\inmuebles_unificado_total_final.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa774eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Dimensiones del dataset: (15960, 25)\n",
      "\n",
      "üîπ Tipos de datos:\n",
      "descripcion           object\n",
      "descripcion_larga     object\n",
      "distrito              object\n",
      "distrito_std          object\n",
      "habitaciones           int64\n",
      "link                  object\n",
      "localidad             object\n",
      "operacion             object\n",
      "origen_archivo        object\n",
      "precio                object\n",
      "tamanio               object\n",
      "has_antig√ºedad         int64\n",
      "has_banos              int64\n",
      "has_garaje             int64\n",
      "has_trastero           int64\n",
      "has_piscina            int64\n",
      "has_terraza            int64\n",
      "precio_num           float64\n",
      "num_banos            float64\n",
      "anio_construccion    float64\n",
      "antiguedad_texto     float64\n",
      "antiguedad_calc      float64\n",
      "antiguedad_final     float64\n",
      "texto_embedding       object\n",
      "embedding             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Estructura del DataFrame\n",
    "\n",
    "print(\" Dimensiones del dataset:\", df.shape)\n",
    "print(\"\\n Tipos de datos:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Porcentaje de nulos por columna:\n",
      "antiguedad_calc      92.03\n",
      "anio_construccion    92.03\n",
      "antiguedad_texto     91.69\n",
      "antiguedad_final     84.45\n",
      "num_banos            80.03\n",
      "descripcion           8.55\n",
      "tamanio               0.90\n",
      "descripcion_larga     0.47\n",
      "has_trastero          0.00\n",
      "texto_embedding       0.00\n",
      "precio_num            0.00\n",
      "has_terraza           0.00\n",
      "has_piscina           0.00\n",
      "has_banos             0.00\n",
      "has_garaje            0.00\n",
      "has_antig√ºedad        0.00\n",
      "precio                0.00\n",
      "origen_archivo        0.00\n",
      "operacion             0.00\n",
      "localidad             0.00\n",
      "link                  0.00\n",
      "habitaciones          0.00\n",
      "distrito_std          0.00\n",
      "distrito              0.00\n",
      "embedding             0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Valores nulos por columna\n",
    "\n",
    "print(\"\\n Porcentaje de nulos por columna:\")\n",
    "print((df.isna().mean() * 100).round(2).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02896a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Estad√≠sticas de columnas num√©ricas:\n",
      "                     count           mean           std     min      25%  \\\n",
      "habitaciones       15960.0       4.734023  1.238237e+01     1.0     2.00   \n",
      "has_antig√ºedad     15960.0       0.001003  3.164750e-02     0.0     0.00   \n",
      "has_banos          15960.0       0.110965  3.140985e-01     0.0     0.00   \n",
      "has_garaje         15960.0       0.075877  2.648098e-01     0.0     0.00   \n",
      "has_trastero       15960.0       0.054135  2.262917e-01     0.0     0.00   \n",
      "has_piscina        15960.0       0.067419  2.507533e-01     0.0     0.00   \n",
      "has_terraza        15960.0       0.160213  3.668150e-01     0.0     0.00   \n",
      "precio_num         15960.0  550259.186779  1.015089e+06  1000.0  2300.00   \n",
      "num_banos           3187.0       1.657358  7.914791e-01     1.0     1.00   \n",
      "anio_construccion   1272.0    1994.226415  3.862009e+01  1900.0  1968.75   \n",
      "antiguedad_texto    1327.0       0.026375  6.417341e-01     0.0     0.00   \n",
      "antiguedad_calc     1272.0      30.773585  3.862009e+01     0.0     0.00   \n",
      "antiguedad_final    2481.0      14.129786  3.003732e+01     0.0     0.00   \n",
      "\n",
      "                        50%        75%         max  \n",
      "habitaciones            3.0       3.00       568.0  \n",
      "has_antig√ºedad          0.0       0.00         1.0  \n",
      "has_banos               0.0       0.00         1.0  \n",
      "has_garaje              0.0       0.00         1.0  \n",
      "has_trastero            0.0       0.00         1.0  \n",
      "has_piscina             0.0       0.00         1.0  \n",
      "has_terraza             0.0       0.00         1.0  \n",
      "precio_num         251535.5  670500.00  15000000.0  \n",
      "num_banos               2.0       2.00        10.0  \n",
      "anio_construccion    2016.0    2025.00      2025.0  \n",
      "antiguedad_texto        0.0       0.00        20.0  \n",
      "antiguedad_calc         9.0      56.25       125.0  \n",
      "antiguedad_final        0.0       7.00       125.0  \n"
     ]
    }
   ],
   "source": [
    "# Descripci√≥n num√©rica\n",
    "\n",
    "print(\"\\n Estad√≠sticas de columnas num√©ricas:\")\n",
    "print(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e84e746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distribuci√≥n de operaciones:\n",
      "operacion\n",
      "venta       9613\n",
      "alquiler    6347\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Ejemplo de distritos:\n",
      "distrito\n",
      "chamartin              1157\n",
      "tetuan                 1146\n",
      "chamberi               1123\n",
      "barrio-de-salamanca    1112\n",
      "centro                 1098\n",
      "retiro                 1064\n",
      "moncloa                1027\n",
      "arganzuela              970\n",
      "ciudad-lineal           912\n",
      "fuencarral              836\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Columnas categ√≥ricas\n",
    "\n",
    "print(\"\\n Distribuci√≥n de operaciones:\")\n",
    "print(df[\"operacion\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\n Ejemplo de distritos:\")\n",
    "print(df[\"distrito\"].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76495d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Resumen de variables extra:\n",
      "                     count         mean        std     min      25%     50%  \\\n",
      "num_banos           3187.0     1.657358   0.791479     1.0     1.00     2.0   \n",
      "anio_construccion   1272.0  1994.226415  38.620089  1900.0  1968.75  2016.0   \n",
      "antiguedad_final    2481.0    14.129786  30.037317     0.0     0.00     0.0   \n",
      "has_garaje         15960.0     0.075877   0.264810     0.0     0.00     0.0   \n",
      "has_trastero       15960.0     0.054135   0.226292     0.0     0.00     0.0   \n",
      "has_piscina        15960.0     0.067419   0.250753     0.0     0.00     0.0   \n",
      "has_terraza        15960.0     0.160213   0.366815     0.0     0.00     0.0   \n",
      "\n",
      "                      75%     max  \n",
      "num_banos             2.0    10.0  \n",
      "anio_construccion  2025.0  2025.0  \n",
      "antiguedad_final      7.0   125.0  \n",
      "has_garaje            0.0     1.0  \n",
      "has_trastero          0.0     1.0  \n",
      "has_piscina           0.0     1.0  \n",
      "has_terraza           0.0     1.0  \n"
     ]
    }
   ],
   "source": [
    "# Variables de inter√©s extra\n",
    "\n",
    "cols_extra = [\"num_banos\", \"anio_construccion\", \"antiguedad_final\", \"has_garaje\", \"has_trastero\", \"has_piscina\", \"has_terraza\"]\n",
    "print(\"\\n Resumen de variables extra:\")\n",
    "print(df[cols_extra].describe(include=\"all\").T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
