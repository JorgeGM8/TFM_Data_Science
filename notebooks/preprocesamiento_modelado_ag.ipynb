{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75f5062",
   "metadata": {},
   "source": [
    "# Preprocesamiento y modelado de datos de viviendas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f3d01",
   "metadata": {},
   "source": [
    "## Importación de librerías y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1996eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import optuna\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e7e59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Distrito</th>\n",
       "      <th>Esperanza_vida</th>\n",
       "      <th>Renta_neta_persona</th>\n",
       "      <th>Renta_neta_hogar</th>\n",
       "      <th>Renta_bruta_persona</th>\n",
       "      <th>Renta_bruta_hogar</th>\n",
       "      <th>Edad_media</th>\n",
       "      <th>Mayores_65anos%</th>\n",
       "      <th>Menores_18anos%</th>\n",
       "      <th>...</th>\n",
       "      <th>Terraza</th>\n",
       "      <th>Planta</th>\n",
       "      <th>Exterior</th>\n",
       "      <th>Ascensor</th>\n",
       "      <th>Ano_construccion</th>\n",
       "      <th>Ano_reforma</th>\n",
       "      <th>Tipo_vivienda</th>\n",
       "      <th>Banos</th>\n",
       "      <th>Precio_predicho</th>\n",
       "      <th>Precio_ajustado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>1</td>\n",
       "      <td>672.875811</td>\n",
       "      <td>657.471490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>1</td>\n",
       "      <td>923.555035</td>\n",
       "      <td>894.792822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>2</td>\n",
       "      <td>1424.913483</td>\n",
       "      <td>1434.552312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>1</td>\n",
       "      <td>2240.808388</td>\n",
       "      <td>2335.359589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>1</td>\n",
       "      <td>1583.237203</td>\n",
       "      <td>1571.481771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ano Distrito  Esperanza_vida  Renta_neta_persona  Renta_neta_hogar  \\\n",
       "0  2011   CENTRO            83.2                 NaN               NaN   \n",
       "1  2011   CENTRO            83.2                 NaN               NaN   \n",
       "2  2011   CENTRO            83.2                 NaN               NaN   \n",
       "3  2011   CENTRO            83.2                 NaN               NaN   \n",
       "4  2011   CENTRO            83.2                 NaN               NaN   \n",
       "\n",
       "   Renta_bruta_persona  Renta_bruta_hogar  Edad_media  Mayores_65anos%  \\\n",
       "0                  NaN                NaN         NaN              NaN   \n",
       "1                  NaN                NaN         NaN              NaN   \n",
       "2                  NaN                NaN         NaN              NaN   \n",
       "3                  NaN                NaN         NaN              NaN   \n",
       "4                  NaN                NaN         NaN              NaN   \n",
       "\n",
       "   Menores_18anos%  ...  Terraza  Planta  Exterior  Ascensor  \\\n",
       "0              NaN  ...    False     0.0     False     False   \n",
       "1              NaN  ...    False     5.0      True      True   \n",
       "2              NaN  ...    False     3.0      True      True   \n",
       "3              NaN  ...    False     4.0      True      True   \n",
       "4              NaN  ...    False     3.0      True      True   \n",
       "\n",
       "   Ano_construccion  Ano_reforma  Tipo_vivienda Banos  Precio_predicho  \\\n",
       "0               NaN          NaN    apartamento     1       672.875811   \n",
       "1               NaN          NaN    apartamento     1       923.555035   \n",
       "2            1910.0          NaN    apartamento     2      1424.913483   \n",
       "3               NaN          NaN    apartamento     1      2240.808388   \n",
       "4            1940.0          NaN    apartamento     1      1583.237203   \n",
       "\n",
       "   Precio_ajustado  \n",
       "0       657.471490  \n",
       "1       894.792822  \n",
       "2      1434.552312  \n",
       "3      2335.359589  \n",
       "4      1571.481771  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inicial = pd.read_csv(\"../data/final/viviendas_2011_2024.csv\")\n",
    "df_inicial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4137604",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf23e1",
   "metadata": {},
   "source": [
    "Revisar notebook [EDA_viviendas_2011_2024](./EDA_viviendas_2011_2024.ipynb) para visualizar el análisis que da lugar a las decisiones tomadas en el preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e260ba",
   "metadata": {},
   "source": [
    "### 1. Eliminar e imputar columnas\n",
    "\n",
    "Eliminación de variables fuertemente correlacionadas, de variables con más del 90% de nulos e imputación de nulos de la columna \"Planta\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b7724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas restantes: ['Ano', 'Distrito', 'Esperanza_vida', 'Mayores_65anos%', 'Menores_18anos%', 'Paro_registrado%', 'Apartamentos_turisticos', 'Densidad_poblacion', 'Zonas_verdes%', 'Habitaciones', 'Operacion', 'Tamano', 'Garaje', 'Trastero', 'Piscina', 'Terraza', 'Planta', 'Exterior', 'Ascensor', 'Tipo_vivienda', 'Banos', 'Precio_ajustado', 'Planta_is_missing']\n"
     ]
    }
   ],
   "source": [
    "df = df_inicial.copy()\n",
    "\n",
    "# Elminación de Ano_construccion y Ano_reforma por exceso de nulos\n",
    "df = df.drop(columns=['Ano_construccion', 'Ano_reforma'])\n",
    "\n",
    "# Crear columna de indicador de nulos para Planta\n",
    "df['Planta_is_missing'] = df['Planta'].isna().astype(int)\n",
    "\n",
    "# Imputar valores nulos con la mediana para Planta (por distrito)\n",
    "df['Planta'] = df.groupby('Distrito')['Planta'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Variables muy correlacionadas y no usadas\n",
    "var_corr = ['Tamano_vivienda_personas', 'Superficie_distrito_ha', 'Edad_media', 'Renta_neta_persona',\n",
    "            'Renta_neta_hogar', 'Renta_bruta_persona', 'Renta_bruta_hogar', 'Precio_predicho']\n",
    "\n",
    "df = df.drop(columns=var_corr)\n",
    "\n",
    "print('Columnas restantes:', df.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec48cdb",
   "metadata": {},
   "source": [
    "### 2. Transformar variables categóricas\n",
    "\n",
    "Se deben pasar las variables categóricas a numéricas para poder procesarlas correctamente con los modelos. Las tres variables categóricas son `Distrito`, `Operacion` y `Tipo_vivienda`. Como no son variables que tengan jerarquía, usaremos dummies para transformarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37772215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ano', 'Esperanza_vida', 'Mayores_65anos%', 'Menores_18anos%',\n",
      "       'Paro_registrado%', 'Apartamentos_turisticos', 'Densidad_poblacion',\n",
      "       'Zonas_verdes%', 'Habitaciones', 'Tamano', 'Garaje', 'Trastero',\n",
      "       'Piscina', 'Terraza', 'Planta', 'Exterior', 'Ascensor', 'Banos',\n",
      "       'Precio_ajustado', 'Planta_is_missing', 'Distrito_BARAJAS',\n",
      "       'Distrito_CARABANCHEL', 'Distrito_CENTRO', 'Distrito_CHAMARTIN',\n",
      "       'Distrito_CHAMBERI', 'Distrito_CIUDADLINEAL',\n",
      "       'Distrito_FUENCARRALELPARDO', 'Distrito_HORTALEZA', 'Distrito_LATINA',\n",
      "       'Distrito_MONCLOAARAVACA', 'Distrito_MORATALAZ',\n",
      "       'Distrito_PUENTEDEVALLECAS', 'Distrito_RETIRO', 'Distrito_SALAMANCA',\n",
      "       'Distrito_SANBLASCANILLEJAS', 'Distrito_TETUAN', 'Distrito_USERA',\n",
      "       'Distrito_VICALVARO', 'Distrito_VILLADEVALLECAS', 'Distrito_VILLAVERDE',\n",
      "       'Operacion_venta', 'Tipo_vivienda_chalet', 'Tipo_vivienda_dúplex',\n",
      "       'Tipo_vivienda_estudio', 'Tipo_vivienda_loft', 'Tipo_vivienda_mansión',\n",
      "       'Tipo_vivienda_tríplex', 'Tipo_vivienda_ático'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd3bb6",
   "metadata": {},
   "source": [
    "### 3. Dividir en entrenamiento, validación y test\n",
    "\n",
    "**DECIDIR Y MODIFICAR - No se puede usar 2023 y 2024 para test o validación porque no tenemos variables input! Solo se pueden usar esos años para evaluar manualmente.**\n",
    "\n",
    "Escogeremos años de 2015 a 2022 (ambos inclusive) para entrenamiento; año 2023 para validación; y año 2024 para test. Como se trata de una serie temporal, haremos la separación directamente en base a los años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e21ea1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (df['Ano'] >= 2015) & (df['Ano'] <= 2021)\n",
    "val_mask = df['Ano'] == 2022\n",
    "#test_mask = df['Ano'] == 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16c79b",
   "metadata": {},
   "source": [
    "### 4. Preparar un pipeline de datos\n",
    "\n",
    "Se utilizará un pipeline para facilitar el manejo de datos y evitar fugas. Para ello, elegimos un escalado robusto para procesar mejor los outliers; y un modelo para entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4905babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def definir_pipeline(modelo) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Función para aplicar escalado y decidir el modelo que se usará.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    modelo : KNN, XGBoost, MLP...\n",
    "        Se pueden incluir los parámetros manualmente dentro del modelo.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        pipeline\n",
    "    \"\"\"\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('modelo', modelo)\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c54b76",
   "metadata": {},
   "source": [
    "**Faltaría a partir de aquí elegir modelos (recomendado por lo menos: baseline con un modelo linear o de distancias; un modelo de árboles; y un MLP). Se puede hacer optimización inteligente con Optuna. Validación para hacer pruebas, test cuando ya se haya optimizado lo posible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cffb9",
   "metadata": {},
   "source": [
    "**Definición de variables, división temporal de datos y función de evaluación del modelo**\n",
    "\n",
    "Variables predictoras (X) y la variable objetivo (y), separando los datos en entrenamiento (2015–2021) y validación (2022) para evitar fuga temporal. \n",
    "Además, se implementa una función de evaluación que entrena el modelo y calcula métricas de rendimiento (MAE, RMSE, MAPE y R²) en ambos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e14fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Filtrar rango completo sin nulos ---\n",
    "df = df.sort_values(by=\"Ano\").reset_index(drop=True)\n",
    "df = df[df['Ano'].between(2015, 2022)].copy()\n",
    "df = df.dropna(subset=[\"Precio_ajustado\"])\n",
    "\n",
    "# --- 2. Crear features temporales ---\n",
    "df = df.sort_values(by=\"Ano\").reset_index(drop=True)\n",
    "df[\"lag_1\"] = df[\"Precio_ajustado\"].shift(1)\n",
    "df[\"lag_2\"] = df[\"Precio_ajustado\"].shift(2)\n",
    "df[\"rolling_mean_3\"] = df[\"Precio_ajustado\"].shift(1).rolling(window=3).mean()\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)  # quitar filas con NA generadas\n",
    "\n",
    "# --- 3. Definir X / y ---\n",
    "TARGET_COL = \"Precio_ajustado\"\n",
    "DROP_COLS = [TARGET_COL]\n",
    "\n",
    "FEATURES = [c for c in df.columns if c not in DROP_COLS]\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59e7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Función de evaluación ---\n",
    "def evaluar(model, X_tr, y_tr, X_va, y_va):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    pred_tr = model.predict(X_tr)\n",
    "    pred_va = model.predict(X_va)\n",
    "\n",
    "    def mape(y_true, y_pred):\n",
    "        eps = 1e-9\n",
    "        return np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + eps))) * 100\n",
    "\n",
    "    return {\n",
    "        \"MAE_train\": mean_absolute_error(y_tr, pred_tr),\n",
    "        \"RMSE_train\": np.sqrt(mean_squared_error(y_tr, pred_tr)),\n",
    "        \"R2_train\": r2_score(y_tr, pred_tr),\n",
    "        \"MAE_val\": mean_absolute_error(y_va, pred_va),\n",
    "        \"RMSE_val\": np.sqrt(mean_squared_error(y_va, pred_va)),\n",
    "        \"MAPE_val_%\": mape(y_va, pred_va),\n",
    "        \"R2_val\": r2_score(y_va, pred_va),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "475f564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 5. Definir modelos para probar ---\n",
    "modelos = {\n",
    "    \"ridge\": definir_pipeline(Ridge(alpha=1.0, random_state=42)),\n",
    "    \"knn\":   definir_pipeline(KNeighborsRegressor(n_neighbors=7, weights=\"distance\", n_jobs=-1)),\n",
    "    \"rf\":    definir_pipeline(RandomForestRegressor(\n",
    "                n_estimators=400, max_depth=None, n_jobs=-1, random_state=42)),\n",
    "    \"hgb\":   definir_pipeline(HistGradientBoostingRegressor(\n",
    "                max_depth=None, learning_rate=0.06, max_iter=500, random_state=42)),\n",
    "    \"mlp\":   definir_pipeline(MLPRegressor(\n",
    "                hidden_layer_sizes=(128, 64),\n",
    "                max_iter=500,\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=1e-3,\n",
    "                early_stopping=True,\n",
    "                n_iter_no_change=20,\n",
    "                random_state=42)),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85258ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. Validación temporal tipo rolling window ---\n",
    "splits = 7\n",
    "tscv = TimeSeriesSplit(n_splits=splits)\n",
    "resultados = {}\n",
    "entrenados = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamientos de prueba\n",
    "for nombre, pipe in modelos.items():\n",
    "    print(f\"Entrenando modelo {nombre}...\")\n",
    "    resultados_modelo = []\n",
    "    n_validacion = 0\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        n_validacion += 1\n",
    "        print(f\"   Split {n_validacion}/{splits}\")\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        metrics = evaluar(pipe, X_train, y_train, X_val, y_val)\n",
    "        resultados_modelo.append(metrics)\n",
    "    resultados[nombre] = resultados_modelo\n",
    "    entrenados[nombre] = pipe\n",
    "\n",
    "# --- 7. Mostrar resultados ---\n",
    "print(\"\\nRESULTADOS:\")\n",
    "ranking = sorted(\n",
    "    resultados.items(),\n",
    "    key=lambda kv: min([m[\"MAE_val\"] for m in kv[1]])  # Ordenar por mejor MAE_val\n",
    ")\n",
    "\n",
    "for nombre, metricas in ranking:\n",
    "    mae_vals = [m[\"MAE_val\"] for m in metricas]\n",
    "    rmse_vals = [m[\"RMSE_val\"] for m in metricas]\n",
    "    r2_vals = [m[\"R2_val\"] for m in metricas]\n",
    "    mape_vals = [m[\"MAPE_val_%\"] for m in metricas]\n",
    "\n",
    "    mae_tr_vals = [m[\"MAE_train\"] for m in metricas]\n",
    "    rmse_tr_vals = [m[\"RMSE_train\"] for m in metricas]\n",
    "    r2_tr_vals = [m[\"R2_train\"] for m in metricas]\n",
    "\n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"  Mejor MAE_val   = {min(mae_vals):.3f}\")\n",
    "    print(f\"  Mejor RMSE_val  = {min(rmse_vals):.3f}\")\n",
    "    print(f\"  Mejor R2_val    = {max(r2_vals):.3f}\")\n",
    "    print(f\"  Mejor MAPE_val  = {min(mape_vals):.2f}%\")\n",
    "    print(f\"  Mejor MAE_train = {min(mae_tr_vals):.3f}\")\n",
    "    print(f\"  Mejor RMSE_train= {min(rmse_tr_vals):.3f}\")\n",
    "    print(f\"  Mejor R2_train  = {max(r2_tr_vals):.3f}\")\n",
    "\n",
    "mejor_nombre = ranking[0][0]\n",
    "mejor_modelo = entrenados[mejor_nombre]\n",
    "print(\"\\nMejor modelo:\", mejor_nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6fb285",
   "metadata": {},
   "source": [
    "**Entrenamiento, evaluación y selección del modelo con mejor rendimiento**\n",
    "\n",
    "Se entrena cada modelo con los datos de entrenamiento y se evalúa su desempeño sobre el conjunto de validación (año 2022) utilizando métricas de error y precisión. Finalmente, se comparan los resultados y se selecciona el modelo con menor MAE, que en este caso corresponde al Random Forest (RF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08108350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== PASO 3 =====\n",
    "\n",
    "\n",
    "\n",
    "# # --- 3.1 Definir X/y y splits temporales ---\n",
    "# TARGET_COL = \"Precio_ajustado\"\n",
    "# DROP_COLS  = [\"Ano\", TARGET_COL]\n",
    "# FEATURES   = [c for c in df.columns if c not in DROP_COLS]\n",
    "\n",
    "# X = df[FEATURES]\n",
    "# y = df[TARGET_COL]\n",
    "\n",
    "# train_mask = (df['Ano'] >= 2015) & (df['Ano'] <= 2021)\n",
    "# val_mask   = (df['Ano'] == 2022)\n",
    "\n",
    "# X_train, y_train = X[train_mask], y[train_mask]\n",
    "# X_val,   y_val   = X[val_mask],   y[val_mask]\n",
    "\n",
    "# # --- 3.2 Función de evaluación (sin usar 'squared' para evitar el error) ---\n",
    "# def evaluar(model, X_tr, y_tr, X_va, y_va):\n",
    "#     model.fit(X_tr, y_tr)\n",
    "#     pred_tr = model.predict(X_tr)\n",
    "#     pred_va = model.predict(X_va)\n",
    "\n",
    "#     def mape(y_true, y_pred):\n",
    "#         eps = 1e-9\n",
    "#         return np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + eps))) * 100\n",
    "\n",
    "#     rmse_train = float(np.sqrt(mean_squared_error(y_tr, pred_tr)))\n",
    "#     rmse_val   = float(np.sqrt(mean_squared_error(y_va, pred_va)))\n",
    "\n",
    "#     return {\n",
    "#         \"MAE_train\": mean_absolute_error(y_tr, pred_tr),\n",
    "#         \"RMSE_train\": rmse_train,\n",
    "#         \"R2_train\": r2_score(y_tr, pred_tr),\n",
    "#         \"MAE_val\": mean_absolute_error(y_va, pred_va),\n",
    "#         \"RMSE_val\": rmse_val,\n",
    "#         \"MAPE_val_%\": mape(y_va, pred_va),\n",
    "#         \"R2_val\": r2_score(y_va, pred_va),\n",
    "#     }\n",
    "\n",
    "# # --- 3.3 Definir modelos (baseline lineal/distancias, árboles, MLP) ---\n",
    "# modelos = {\n",
    "#     \"ridge\": definir_pipeline(Ridge(alpha=1.0, random_state=42)),\n",
    "#     \"knn\":   definir_pipeline(KNeighborsRegressor(n_neighbors=7, weights=\"distance\")),\n",
    "#     \"rf\":    definir_pipeline(RandomForestRegressor(\n",
    "#                 n_estimators=400, max_depth=None, n_jobs=-1, random_state=42)),\n",
    "#     \"hgb\":   definir_pipeline(HistGradientBoostingRegressor(\n",
    "#                 max_depth=None, learning_rate=0.06, max_iter=500, random_state=42)),\n",
    "#     \"mlp\":   definir_pipeline(MLPRegressor(\n",
    "#                 hidden_layer_sizes=(128, 64),\n",
    "#                 max_iter=400,\n",
    "#                 activation=\"relu\",\n",
    "#                 learning_rate_init=1e-3,\n",
    "#                 early_stopping=True,\n",
    "#                 n_iter_no_change=20,\n",
    "#                 random_state=42)),\n",
    "# }\n",
    "\n",
    "# # --- 3.4 Entrenar y rankear por MAE de validación ---\n",
    "# resultados = {}\n",
    "# entrenados = {}\n",
    "\n",
    "# for nombre, pipe in modelos.items():\n",
    "#     print(f\"Entrenando modelo: {nombre}\")\n",
    "#     mets = evaluar(pipe, X_train, y_train, X_val, y_val)\n",
    "#     resultados[nombre] = mets\n",
    "#     entrenados[nombre] = pipe  # queda entrenado dentro de evaluar\n",
    "\n",
    "# ranking = sorted(resultados.items(), key=lambda kv: kv[1][\"MAE_val\"])\n",
    "# for nombre, m in ranking:\n",
    "#     print(f\"{nombre:>4} | MAE_val={m['MAE_val']:.3f} | RMSE_val={m['RMSE_val']:.3f} | \"\n",
    "#           f\"MAPE_val={m['MAPE_val_%']:.2f}% | R2_val={m['R2_val']:.3f}\")\n",
    "\n",
    "# mejor_nombre = ranking[0][0]\n",
    "# mejor_modelo = entrenados[mejor_nombre]\n",
    "# print(\"\\nMejor modelo:\", mejor_nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e7f7d",
   "metadata": {},
   "source": [
    "**Optimización de hiperparámetros del modelo Random Forest mediante Optuna**\n",
    "\n",
    "Se utiliza la librería Optuna para ajustar automáticamente los hiperparámetros del modelo Random Forest. A través de múltiples iteraciones, se buscan las combinaciones que minimicen el error absoluto medio (MAE) en validación, obteniendo así el conjunto de parámetros con el mejor rendimiento predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a54794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 01:46:03,617] A new study created in memory with name: Optimizacion_rf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3658bd9532744fe7a41e2c9aa5b04b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Paso 4: Optimización con Optuna (Random Forest) =====\n",
    "\n",
    "# Define los splits fuera de la función para no recrearlos en cada trial\n",
    "tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000, step=100),\n",
    "        \"max_depth\": trial.suggest_categorical(\"max_depth\", [5, 10, 20, 30, 40, 50]),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", 0.8, 1.0]),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    pipe = definir_pipeline(RandomForestRegressor(**params))\n",
    "\n",
    "    maes = []\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        mets = evaluar(pipe, X_train, y_train, X_val, y_val)\n",
    "        maes.append(mets[\"MAE_val\"])\n",
    "\n",
    "    return np.mean(maes)  # usar promedio del MAE en los splits\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"Optimizacion_rf\")\n",
    "study.optimize(objective_rf, n_trials=20, show_progress_bar=True, n_jobs=-1)\n",
    "\n",
    "print(\"Best MAE_val:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e6a1e",
   "metadata": {},
   "source": [
    "**Entrenamiento del modelo Random Forest final con los mejores hiperparámetros**\n",
    "\n",
    "Se entrena el modelo Random Forest utilizando los hiperparámetros óptimos encontrados con Optuna. El modelo final se integra en un pipeline con escalado robusto y se ajusta sobre los datos de entrenamiento completos, obteniendo así la versión definitiva lista para evaluación y predicciones futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Entrenar el mejor modelo RF final =====\n",
    "\n",
    "rf_final = definir_pipeline(RandomForestRegressor(**study.best_params))\n",
    "\n",
    "# Entrenar con todos los datos (ya que es una serie temporal)\n",
    "rf_final.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202b555",
   "metadata": {},
   "source": [
    "Guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b4c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/rf_final.pkl') as f:\n",
    "    pickle.dump(rf_final, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6ad11",
   "metadata": {},
   "source": [
    "**Comparativa de desempeño entre el modelo base y el modelo optimizado**\n",
    "\n",
    "Se comparan los resultados del modelo Random Forest inicial frente al modelo optimizado tras la búsqueda de hiperparámetros. El modelo ajustado muestra una mejora en el MAE y MAPE de validación, manteniendo un R² alto, lo que confirma una mayor precisión y mejor capacidad de generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base = entrenados[\"rf\"]  # el modelo base antes del tuning\n",
    "\n",
    "base_mets = resultados[\"rf\"]\n",
    "tuned_mets = evaluar(rf_final, X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"\\n--- Comparativa Random Forest ---\")\n",
    "print(\"Base :\", base_mets)\n",
    "print(\"Tuned:\", tuned_mets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49e859",
   "metadata": {},
   "source": [
    "**Análisis de la importancia de variables en el modelo Random Forest**\n",
    "\n",
    "Se extraen y visualizan las variables con mayor peso en el modelo final de Random Forest. Este análisis permite identificar los factores que más influyen en la predicción del precio ajustado, mostrando las 15 variables más relevantes mediante una tabla y un gráfico de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extraer importancias\n",
    "importancias = rf_final.named_steps['modelo'].feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Crear DataFrame ordenado\n",
    "imp_df = pd.DataFrame({\n",
    "    'Variable': features,\n",
    "    'Importancia': importancias\n",
    "}).sort_values(by='Importancia', ascending=False).head(15)\n",
    "\n",
    "# Mostrar tabla y gráfico\n",
    "display(imp_df)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.barh(imp_df['Variable'], imp_df['Importancia'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 15 variables más importantes en el modelo Random Forest')\n",
    "plt.xlabel('Importancia')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
