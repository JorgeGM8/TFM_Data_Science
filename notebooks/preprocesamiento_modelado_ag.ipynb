{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75f5062",
   "metadata": {},
   "source": [
    "# Preprocesamiento y modelado de datos de viviendas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f3d01",
   "metadata": {},
   "source": [
    "## Importación de librerías y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1996eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.base import clone\n",
    "import optuna\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e7e59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Distrito</th>\n",
       "      <th>Esperanza_vida</th>\n",
       "      <th>Renta_neta_persona</th>\n",
       "      <th>Renta_neta_hogar</th>\n",
       "      <th>Renta_bruta_persona</th>\n",
       "      <th>Renta_bruta_hogar</th>\n",
       "      <th>Edad_media</th>\n",
       "      <th>Mayores_65anos%</th>\n",
       "      <th>Menores_18anos%</th>\n",
       "      <th>...</th>\n",
       "      <th>Terraza</th>\n",
       "      <th>Planta</th>\n",
       "      <th>Exterior</th>\n",
       "      <th>Ascensor</th>\n",
       "      <th>Ano_construccion</th>\n",
       "      <th>Ano_reforma</th>\n",
       "      <th>Tipo_vivienda</th>\n",
       "      <th>Banos</th>\n",
       "      <th>Precio_predicho</th>\n",
       "      <th>Precio_ajustado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>1</td>\n",
       "      <td>672.875811</td>\n",
       "      <td>657.471490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>1</td>\n",
       "      <td>923.555035</td>\n",
       "      <td>894.792822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>2</td>\n",
       "      <td>1424.913483</td>\n",
       "      <td>1434.552312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>1</td>\n",
       "      <td>2240.808388</td>\n",
       "      <td>2335.359589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>CENTRO</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apartamento</td>\n",
       "      <td>1</td>\n",
       "      <td>1583.237203</td>\n",
       "      <td>1571.481771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ano Distrito  Esperanza_vida  Renta_neta_persona  Renta_neta_hogar  \\\n",
       "0  2011   CENTRO            83.2                 NaN               NaN   \n",
       "1  2011   CENTRO            83.2                 NaN               NaN   \n",
       "2  2011   CENTRO            83.2                 NaN               NaN   \n",
       "3  2011   CENTRO            83.2                 NaN               NaN   \n",
       "4  2011   CENTRO            83.2                 NaN               NaN   \n",
       "\n",
       "   Renta_bruta_persona  Renta_bruta_hogar  Edad_media  Mayores_65anos%  \\\n",
       "0                  NaN                NaN         NaN              NaN   \n",
       "1                  NaN                NaN         NaN              NaN   \n",
       "2                  NaN                NaN         NaN              NaN   \n",
       "3                  NaN                NaN         NaN              NaN   \n",
       "4                  NaN                NaN         NaN              NaN   \n",
       "\n",
       "   Menores_18anos%  ...  Terraza  Planta  Exterior  Ascensor  \\\n",
       "0              NaN  ...    False     0.0     False     False   \n",
       "1              NaN  ...    False     5.0      True      True   \n",
       "2              NaN  ...    False     3.0      True      True   \n",
       "3              NaN  ...    False     4.0      True      True   \n",
       "4              NaN  ...    False     3.0      True      True   \n",
       "\n",
       "   Ano_construccion  Ano_reforma  Tipo_vivienda Banos  Precio_predicho  \\\n",
       "0               NaN          NaN    apartamento     1       672.875811   \n",
       "1               NaN          NaN    apartamento     1       923.555035   \n",
       "2            1910.0          NaN    apartamento     2      1424.913483   \n",
       "3               NaN          NaN    apartamento     1      2240.808388   \n",
       "4            1940.0          NaN    apartamento     1      1583.237203   \n",
       "\n",
       "   Precio_ajustado  \n",
       "0       657.471490  \n",
       "1       894.792822  \n",
       "2      1434.552312  \n",
       "3      2335.359589  \n",
       "4      1571.481771  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inicial = pd.read_csv(\"../data/final/viviendas_2011_2024.csv\")\n",
    "df_inicial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4137604",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf23e1",
   "metadata": {},
   "source": [
    "Revisar notebook [EDA_viviendas_2011_2024](./EDA_viviendas_2011_2024.ipynb) para visualizar el análisis que da lugar a las decisiones tomadas en el preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e260ba",
   "metadata": {},
   "source": [
    "### 1. Eliminar e imputar columnas\n",
    "\n",
    "Eliminación de variables fuertemente correlacionadas, de variables con más del 90% de nulos e imputación de nulos de la columna \"Planta\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b7724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas restantes: ['Ano', 'Distrito', 'Esperanza_vida', 'Mayores_65anos%', 'Menores_18anos%', 'Paro_registrado%', 'Apartamentos_turisticos', 'Superficie_distrito_ha', 'Zonas_verdes%', 'Habitaciones', 'Operacion', 'Tamano', 'Garaje', 'Trastero', 'Piscina', 'Terraza', 'Planta', 'Exterior', 'Ascensor', 'Tipo_vivienda', 'Banos', 'Precio_ajustado', 'Planta_is_missing']\n"
     ]
    }
   ],
   "source": [
    "df = df_inicial.copy()\n",
    "\n",
    "# Seleccionamos rango con el que nos interesa trabajar\n",
    "df = df[df['Ano'] >= 2015]\n",
    "\n",
    "# Elminación de Ano_construccion y Ano_reforma por exceso de nulos\n",
    "df = df.drop(columns=['Ano_construccion', 'Ano_reforma'])\n",
    "\n",
    "# Crear columna de indicador de nulos para Planta\n",
    "df['Planta_is_missing'] = df['Planta'].isna().astype(int)\n",
    "\n",
    "# Imputar valores nulos con la mediana para Planta (por distrito)\n",
    "df['Planta'] = df.groupby('Distrito')['Planta'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Variables muy correlacionadas y no usadas\n",
    "var_corr = ['Tamano_vivienda_personas', 'Densidad_poblacion', 'Edad_media', 'Renta_neta_persona',\n",
    "            'Renta_neta_hogar', 'Renta_bruta_persona', 'Renta_bruta_hogar', 'Precio_predicho']\n",
    "\n",
    "df = df.drop(columns=var_corr)\n",
    "\n",
    "print('Columnas restantes:', df.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f403d",
   "metadata": {},
   "source": [
    "Imputamos variables socioeconómicas faltantes en 2023 y 2024 para poder hacer una predicción de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522e9059",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_faltantes = ['Mayores_65anos%', 'Menores_18anos%', 'Paro_registrado%']\n",
    "\n",
    "# Añadimos columna de indicador de nulos para cada variable\n",
    "for var in vars_faltantes:\n",
    "    df[f\"{var}_is_missing\"] = df[var].isna().astype(int)\n",
    "\n",
    "df[vars_faltantes] = (\n",
    "    df.groupby(\"Distrito\")[vars_faltantes]\n",
    "      .apply(lambda x: x.ffill().bfill())\n",
    "      .reset_index(level=0, drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a259d8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Tipo  Nulos  Nulos_%\n",
      "Ano                            int64      0      0.0\n",
      "Distrito                      object      0      0.0\n",
      "Esperanza_vida               float64      0      0.0\n",
      "Mayores_65anos%              float64      0      0.0\n",
      "Menores_18anos%              float64      0      0.0\n",
      "Paro_registrado%             float64      0      0.0\n",
      "Apartamentos_turisticos      float64      0      0.0\n",
      "Superficie_distrito_ha       float64      0      0.0\n",
      "Zonas_verdes%                float64      0      0.0\n",
      "Habitaciones                   int64      0      0.0\n",
      "Operacion                     object      0      0.0\n",
      "Tamano                       float64      0      0.0\n",
      "Garaje                          bool      0      0.0\n",
      "Trastero                        bool      0      0.0\n",
      "Piscina                         bool      0      0.0\n",
      "Terraza                         bool      0      0.0\n",
      "Planta                       float64      0      0.0\n",
      "Exterior                        bool      0      0.0\n",
      "Ascensor                        bool      0      0.0\n",
      "Tipo_vivienda                 object      0      0.0\n",
      "Banos                          int64      0      0.0\n",
      "Precio_ajustado              float64      0      0.0\n",
      "Planta_is_missing              int64      0      0.0\n",
      "Mayores_65anos%_is_missing     int64      0      0.0\n",
      "Menores_18anos%_is_missing     int64      0      0.0\n",
      "Paro_registrado%_is_missing    int64      0      0.0\n"
     ]
    }
   ],
   "source": [
    "resumen = pd.DataFrame({\n",
    "    \"Tipo\": df.dtypes,\n",
    "    \"Nulos\": df.isna().sum(),\n",
    "    \"Nulos_%\": (df.isna().mean()*100).round(2)\n",
    "})\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec48cdb",
   "metadata": {},
   "source": [
    "### 2. Transformar variables categóricas\n",
    "\n",
    "Se deben pasar las variables categóricas a numéricas para poder procesarlas correctamente con los modelos. Las tres variables categóricas son `Distrito`, `Operacion` y `Tipo_vivienda`. Como no son variables que tengan jerarquía, usaremos dummies para transformarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37772215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Ano', 'Esperanza_vida', 'Mayores_65anos%', 'Menores_18anos%',\n",
      "       'Paro_registrado%', 'Apartamentos_turisticos', 'Superficie_distrito_ha',\n",
      "       'Zonas_verdes%', 'Habitaciones', 'Tamano', 'Garaje', 'Trastero',\n",
      "       'Piscina', 'Terraza', 'Planta', 'Exterior', 'Ascensor', 'Banos',\n",
      "       'Precio_ajustado', 'Planta_is_missing', 'Mayores_65anos%_is_missing',\n",
      "       'Menores_18anos%_is_missing', 'Paro_registrado%_is_missing',\n",
      "       'Distrito_BARAJAS', 'Distrito_CARABANCHEL', 'Distrito_CENTRO',\n",
      "       'Distrito_CHAMARTIN', 'Distrito_CHAMBERI', 'Distrito_CIUDADLINEAL',\n",
      "       'Distrito_FUENCARRALELPARDO', 'Distrito_HORTALEZA', 'Distrito_LATINA',\n",
      "       'Distrito_MONCLOAARAVACA', 'Distrito_MORATALAZ',\n",
      "       'Distrito_PUENTEDEVALLECAS', 'Distrito_RETIRO', 'Distrito_SALAMANCA',\n",
      "       'Distrito_SANBLASCANILLEJAS', 'Distrito_TETUAN', 'Distrito_USERA',\n",
      "       'Distrito_VICALVARO', 'Distrito_VILLADEVALLECAS', 'Distrito_VILLAVERDE',\n",
      "       'Operacion_venta', 'Tipo_vivienda_chalet', 'Tipo_vivienda_dúplex',\n",
      "       'Tipo_vivienda_estudio', 'Tipo_vivienda_loft', 'Tipo_vivienda_mansión',\n",
      "       'Tipo_vivienda_tríplex', 'Tipo_vivienda_ático'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd3bb6",
   "metadata": {},
   "source": [
    "### 3. Dividir en entrenamiento, validación y test\n",
    "\n",
    "Escogeremos años de 2015 a 2022 (ambos inclusive) para entrenamiento; y años 2023 y 2024 para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e21ea1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = (df[\"Ano\"] >= 2023)\n",
    "df_test = df[test_mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16c79b",
   "metadata": {},
   "source": [
    "### 4. Preparar un pipeline de datos\n",
    "\n",
    "Se utilizará un pipeline para facilitar el manejo de datos y evitar fugas. Para ello, elegimos un escalado robusto para procesar mejor los outliers; y un modelo para entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4905babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def definir_pipeline(modelo) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Función para aplicar escalado y decidir el modelo que se usará.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    modelo : KNN, XGBoost, MLP...\n",
    "        Se pueden incluir los parámetros manualmente dentro del modelo.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        pipeline\n",
    "    \"\"\"\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('modelo', modelo)\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c54b76",
   "metadata": {},
   "source": [
    "**Faltaría a partir de aquí elegir modelos (recomendado por lo menos: baseline con un modelo linear o de distancias; un modelo de árboles; y un MLP). Se puede hacer optimización inteligente con Optuna. Validación para hacer pruebas, test cuando ya se haya optimizado lo posible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cffb9",
   "metadata": {},
   "source": [
    "**Definición de variables, división temporal de datos y función de evaluación del modelo**\n",
    "\n",
    "Variables predictoras (X) y la variable objetivo (y), separando los datos en entrenamiento (2015–2021) y validación (2022) para evitar fuga temporal. \n",
    "Además, se implementa una función de evaluación que entrena el modelo y calcula métricas de rendimiento (MAE, RMSE, MAPE y R²) en ambos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e14fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Filtrar rango completo sin nulos ---\n",
    "df = df.sort_values(by=\"Ano\").reset_index(drop=True)\n",
    "df = df[df['Ano'] >= 2015].copy()\n",
    "df = df.dropna(subset=[\"Precio_ajustado\"])\n",
    "\n",
    "# --- 2. Crear features temporales ---\n",
    "df = df.sort_values(by=\"Ano\").reset_index(drop=True)\n",
    "\n",
    "mask_train = (df[\"Ano\"] <= 2022)\n",
    "df.loc[mask_train, \"lag_1\"] = df.loc[mask_train, \"Precio_ajustado\"].shift(1)\n",
    "df.loc[mask_train, \"lag_2\"] = df.loc[mask_train, \"Precio_ajustado\"].shift(2)\n",
    "df.loc[mask_train, \"rolling_mean_3\"] = (\n",
    "    df.loc[mask_train, \"Precio_ajustado\"].shift(1).rolling(window=3).mean()\n",
    ")\n",
    "df = df.dropna(subset=[\"lag_1\", \"lag_2\", \"rolling_mean_3\"]).reset_index(drop=True)  # quitar filas con NA generadas\n",
    "\n",
    "# --- 3. Definir X / y ---\n",
    "TARGET_COL = \"Precio_ajustado\"\n",
    "DROP_COLS = [\"Ano\", TARGET_COL] # Eliminamos año porque ya tenemos lags temporales y media móvil\n",
    "\n",
    "FEATURES = [c for c in df.columns if c not in DROP_COLS]\n",
    "\n",
    "# Separación temporal\n",
    "mask_train = (df[\"Ano\"] <= 2022)\n",
    "mask_test  = (df[\"Ano\"] >= 2023)\n",
    "\n",
    "X_train = df.loc[mask_train, FEATURES]\n",
    "y_train = df.loc[mask_train, TARGET_COL]\n",
    "X_test  = df.loc[mask_test, FEATURES]\n",
    "y_test  = df.loc[mask_test, TARGET_COL]\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d59e7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Función de evaluación ---\n",
    "def evaluar(model, X_tr, y_tr, X_va, y_va):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    pred_tr = model.predict(X_tr)\n",
    "    pred_va = model.predict(X_va)\n",
    "\n",
    "    def mape(y_true, y_pred):\n",
    "        eps = 1e-9\n",
    "        return np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + eps))) * 100\n",
    "\n",
    "    return {\n",
    "        \"MAE_train\": mean_absolute_error(y_tr, pred_tr),\n",
    "        \"RMSE_train\": np.sqrt(mean_squared_error(y_tr, pred_tr)),\n",
    "        \"R2_train\": r2_score(y_tr, pred_tr),\n",
    "        \"MAE_val\": mean_absolute_error(y_va, pred_va),\n",
    "        \"RMSE_val\": np.sqrt(mean_squared_error(y_va, pred_va)),\n",
    "        \"MAPE_val_%\": mape(y_va, pred_va),\n",
    "        \"R2_val\": r2_score(y_va, pred_va),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475f564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 5. Definir modelos para probar ---\n",
    "modelos = {\n",
    "    \"ridge\": definir_pipeline(Ridge(alpha=1.0, random_state=42)),\n",
    "    \"knn\":   definir_pipeline(KNeighborsRegressor(n_neighbors=7, weights=\"distance\", n_jobs=-1)),\n",
    "    \"rf\":    definir_pipeline(RandomForestRegressor(\n",
    "                n_estimators=400, max_depth=None, n_jobs=-1, random_state=42)),\n",
    "    \"hgb\":   definir_pipeline(HistGradientBoostingRegressor(\n",
    "                max_depth=None, learning_rate=0.06, max_iter=500, random_state=42)),\n",
    "    \"mlp\":   definir_pipeline(MLPRegressor(\n",
    "                hidden_layer_sizes=(128, 64),\n",
    "                max_iter=500,\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=1e-3,\n",
    "                early_stopping=True,\n",
    "                n_iter_no_change=20,\n",
    "                random_state=42)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85258ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. Validación temporal tipo rolling window ---\n",
    "splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=splits)\n",
    "resultados = {}\n",
    "entrenados = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo ridge...\n",
      "   Split 1/5\n",
      "   Split 2/5\n",
      "   Split 3/5\n",
      "   Split 4/5\n",
      "   Split 5/5\n",
      "Entrenando modelo knn...\n",
      "   Split 1/5\n",
      "   Split 2/5\n",
      "   Split 3/5\n",
      "   Split 4/5\n",
      "   Split 5/5\n",
      "Entrenando modelo rf...\n",
      "   Split 1/5\n",
      "   Split 2/5\n",
      "   Split 3/5\n",
      "   Split 4/5\n",
      "   Split 5/5\n"
     ]
    }
   ],
   "source": [
    "# Entrenamientos de prueba\n",
    "for nombre, pipe in modelos.items():\n",
    "    print(f\"Entrenando modelo {nombre}...\")\n",
    "    resultados_modelo = []\n",
    "    n_validacion = 0\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        n_validacion += 1\n",
    "        print(f\"   Split {n_validacion}/{splits}\")\n",
    "\n",
    "        pipe_cv = clone(pipe) # Clonar pipeline cada split para evitar sesgos\n",
    "\n",
    "        X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        metrics = evaluar(pipe_cv, X_tr, y_tr, X_val, y_val)\n",
    "        resultados_modelo.append(metrics)\n",
    "\n",
    "    resultados[nombre] = resultados_modelo\n",
    "\n",
    "    # Entrenamiento final con todo el conjunto\n",
    "    pipe_final = clone(pipe).fit(X_train, y_train)\n",
    "    entrenados[nombre] = pipe_final\n",
    "\n",
    "# --- 7. Mostrar resultados ---\n",
    "print(\"\\nRESULTADOS DE EVALUACIÓN 2015-2022:\")\n",
    "ranking = sorted(\n",
    "    resultados.items(),\n",
    "    key=lambda kv: min([m[\"MAE_val\"] for m in kv[1]])  # Ordenar por mejor MAE_val\n",
    ")\n",
    "\n",
    "for nombre, metricas in ranking:\n",
    "    mae_vals = [m[\"MAE_val\"] for m in metricas]\n",
    "    rmse_vals = [m[\"RMSE_val\"] for m in metricas]\n",
    "    r2_vals = [m[\"R2_val\"] for m in metricas]\n",
    "    mape_vals = [m[\"MAPE_val_%\"] for m in metricas]\n",
    "\n",
    "    mae_tr_vals = [m[\"MAE_train\"] for m in metricas]\n",
    "    rmse_tr_vals = [m[\"RMSE_train\"] for m in metricas]\n",
    "    r2_tr_vals = [m[\"R2_train\"] for m in metricas]\n",
    "\n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"  Mejor MAE_val   = {min(mae_vals):.3f}\")\n",
    "    print(f\"  Mejor RMSE_val  = {min(rmse_vals):.3f}\")\n",
    "    print(f\"  Mejor R2_val    = {max(r2_vals):.3f}\")\n",
    "    print(f\"  Mejor MAPE_val  = {min(mape_vals):.2f}%\")\n",
    "    print(f\"  Mejor MAE_train = {min(mae_tr_vals):.3f}\")\n",
    "    print(f\"  Mejor RMSE_train= {min(rmse_tr_vals):.3f}\")\n",
    "    print(f\"  Mejor R2_train  = {max(r2_tr_vals):.3f}\")\n",
    "\n",
    "mejor_nombre = ranking[0][0]\n",
    "mejor_modelo = entrenados[mejor_nombre]\n",
    "print(\"\\nMejor modelo:\", mejor_nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6fb285",
   "metadata": {},
   "source": [
    "**Entrenamiento, evaluación y selección del modelo con mejor rendimiento**\n",
    "\n",
    "Se entrena cada modelo con los datos de entrenamiento y se evalúa su desempeño sobre el conjunto de validación (año 2022) utilizando métricas de error y precisión. Finalmente, se comparan los resultados y se selecciona el modelo con menor MAE, que en este caso corresponde al Random Forest (RF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08108350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== PASO 3 =====\n",
    "\n",
    "\n",
    "\n",
    "# # --- 3.1 Definir X/y y splits temporales ---\n",
    "# TARGET_COL = \"Precio_ajustado\"\n",
    "# DROP_COLS  = [\"Ano\", TARGET_COL]\n",
    "# FEATURES   = [c for c in df.columns if c not in DROP_COLS]\n",
    "\n",
    "# X = df[FEATURES]\n",
    "# y = df[TARGET_COL]\n",
    "\n",
    "# train_mask = (df['Ano'] >= 2015) & (df['Ano'] <= 2021)\n",
    "# val_mask   = (df['Ano'] == 2022)\n",
    "\n",
    "# X_train, y_train = X[train_mask], y[train_mask]\n",
    "# X_val,   y_val   = X[val_mask],   y[val_mask]\n",
    "\n",
    "# # --- 3.2 Función de evaluación (sin usar 'squared' para evitar el error) ---\n",
    "# def evaluar(model, X_tr, y_tr, X_va, y_va):\n",
    "#     model.fit(X_tr, y_tr)\n",
    "#     pred_tr = model.predict(X_tr)\n",
    "#     pred_va = model.predict(X_va)\n",
    "\n",
    "#     def mape(y_true, y_pred):\n",
    "#         eps = 1e-9\n",
    "#         return np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + eps))) * 100\n",
    "\n",
    "#     rmse_train = float(np.sqrt(mean_squared_error(y_tr, pred_tr)))\n",
    "#     rmse_val   = float(np.sqrt(mean_squared_error(y_va, pred_va)))\n",
    "\n",
    "#     return {\n",
    "#         \"MAE_train\": mean_absolute_error(y_tr, pred_tr),\n",
    "#         \"RMSE_train\": rmse_train,\n",
    "#         \"R2_train\": r2_score(y_tr, pred_tr),\n",
    "#         \"MAE_val\": mean_absolute_error(y_va, pred_va),\n",
    "#         \"RMSE_val\": rmse_val,\n",
    "#         \"MAPE_val_%\": mape(y_va, pred_va),\n",
    "#         \"R2_val\": r2_score(y_va, pred_va),\n",
    "#     }\n",
    "\n",
    "# # --- 3.3 Definir modelos (baseline lineal/distancias, árboles, MLP) ---\n",
    "# modelos = {\n",
    "#     \"ridge\": definir_pipeline(Ridge(alpha=1.0, random_state=42)),\n",
    "#     \"knn\":   definir_pipeline(KNeighborsRegressor(n_neighbors=7, weights=\"distance\")),\n",
    "#     \"rf\":    definir_pipeline(RandomForestRegressor(\n",
    "#                 n_estimators=400, max_depth=None, n_jobs=-1, random_state=42)),\n",
    "#     \"hgb\":   definir_pipeline(HistGradientBoostingRegressor(\n",
    "#                 max_depth=None, learning_rate=0.06, max_iter=500, random_state=42)),\n",
    "#     \"mlp\":   definir_pipeline(MLPRegressor(\n",
    "#                 hidden_layer_sizes=(128, 64),\n",
    "#                 max_iter=400,\n",
    "#                 activation=\"relu\",\n",
    "#                 learning_rate_init=1e-3,\n",
    "#                 early_stopping=True,\n",
    "#                 n_iter_no_change=20,\n",
    "#                 random_state=42)),\n",
    "# }\n",
    "\n",
    "# # --- 3.4 Entrenar y rankear por MAE de validación ---\n",
    "# resultados = {}\n",
    "# entrenados = {}\n",
    "\n",
    "# for nombre, pipe in modelos.items():\n",
    "#     print(f\"Entrenando modelo: {nombre}\")\n",
    "#     mets = evaluar(pipe, X_train, y_train, X_val, y_val)\n",
    "#     resultados[nombre] = mets\n",
    "#     entrenados[nombre] = pipe  # queda entrenado dentro de evaluar\n",
    "\n",
    "# ranking = sorted(resultados.items(), key=lambda kv: kv[1][\"MAE_val\"])\n",
    "# for nombre, m in ranking:\n",
    "#     print(f\"{nombre:>4} | MAE_val={m['MAE_val']:.3f} | RMSE_val={m['RMSE_val']:.3f} | \"\n",
    "#           f\"MAPE_val={m['MAPE_val_%']:.2f}% | R2_val={m['R2_val']:.3f}\")\n",
    "\n",
    "# mejor_nombre = ranking[0][0]\n",
    "# mejor_modelo = entrenados[mejor_nombre]\n",
    "# print(\"\\nMejor modelo:\", mejor_nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e7f7d",
   "metadata": {},
   "source": [
    "**Optimización de hiperparámetros del modelo Random Forest mediante Optuna**\n",
    "\n",
    "Se utiliza la librería Optuna para ajustar automáticamente los hiperparámetros del modelo Random Forest. A través de múltiples iteraciones, se buscan las combinaciones que minimicen el error absoluto medio (MAE) en validación, obteniendo así el conjunto de parámetros con el mejor rendimiento predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a54794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Paso 4: Optimización con Optuna (Random Forest) =====\n",
    "\n",
    "# Definir los splits fuera de la función para no recrearlos en cada trial\n",
    "tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000, step=100),\n",
    "        \"max_depth\": trial.suggest_categorical(\"max_depth\", [5, 10, 20, 30, 40, 50]),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", 0.8, 1.0]),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    pipe = definir_pipeline(RandomForestRegressor(**params))\n",
    "\n",
    "    maes = []\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        pipe_cv = clone(pipe) # Clonar pipeline en cada split para evitar sesgos\n",
    "\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        mets = evaluar(pipe_cv, X_tr, y_tr, X_val, y_val)\n",
    "        maes.append(mets[\"MAE_val\"])\n",
    "\n",
    "    return np.mean(maes)  # Usar promedio del MAE en los splits como métrica de validación\n",
    "\n",
    "# Crear estudio de Optuna y ejecutarlo\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"Optimizacion_rf\")\n",
    "study.optimize(objective_rf, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "print(\"Best MAE_val:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e6a1e",
   "metadata": {},
   "source": [
    "**Entrenamiento del modelo Random Forest final con los mejores hiperparámetros**\n",
    "\n",
    "Se entrena el modelo Random Forest utilizando los hiperparámetros óptimos encontrados con Optuna. El modelo final se integra en un pipeline con escalado robusto y se ajusta sobre los datos de entrenamiento completos, obteniendo así la versión definitiva lista para evaluación y predicciones futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Entrenar el mejor modelo RF final =====\n",
    "\n",
    "rf_final = definir_pipeline(RandomForestRegressor(**study.best_params))\n",
    "\n",
    "# Entrenar con todos los datos (ya que es una serie temporal)\n",
    "rf_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab59006",
   "metadata": {},
   "source": [
    "Evaluación en 2023 y 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Evaluación en 2023 ---\")\n",
    "mask_2023 = df[\"Ano\"] == 2023\n",
    "eval_2023 = evaluar(rf_final, X_train, y_train, X.loc[mask_2023, FEATURES], y.loc[mask_2023])\n",
    "print(eval_2023)\n",
    "\n",
    "print(\"\\n--- Evaluación en 2024 ---\")\n",
    "mask_2024 = df[\"Ano\"] == 2024\n",
    "eval_2024 = evaluar(rf_final, X_train, y_train, X.loc[mask_2024, FEATURES], y.loc[mask_2024])\n",
    "print(eval_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccdd647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1202b555",
   "metadata": {},
   "source": [
    "Guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b4c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/rf_final.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_final, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6ad11",
   "metadata": {},
   "source": [
    "**Comparativa de desempeño entre el modelo base y el modelo optimizado**\n",
    "\n",
    "Se comparan los resultados del modelo Random Forest inicial frente al modelo optimizado tras la búsqueda de hiperparámetros. El modelo ajustado muestra una mejora en el MAE y MAPE de validación, manteniendo un R² alto, lo que confirma una mayor precisión y mejor capacidad de generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base = entrenados[\"rf\"]  # el modelo base antes del tuning\n",
    "\n",
    "base_mets = resultados[\"rf\"]\n",
    "tuned_mets = evaluar(rf_final, X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"\\n--- Comparativa Random Forest ---\")\n",
    "print(\"Base :\", base_mets)\n",
    "print(\"Tuned:\", tuned_mets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49e859",
   "metadata": {},
   "source": [
    "**Análisis de la importancia de variables en el modelo Random Forest**\n",
    "\n",
    "Se extraen y visualizan las variables con mayor peso en el modelo final de Random Forest. Este análisis permite identificar los factores que más influyen en la predicción del precio ajustado, mostrando las 15 variables más relevantes mediante una tabla y un gráfico de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extraer importancias\n",
    "importancias = rf_final.named_steps['modelo'].feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Crear DataFrame ordenado\n",
    "imp_df = pd.DataFrame({\n",
    "    'Variable': features,\n",
    "    'Importancia': importancias\n",
    "}).sort_values(by='Importancia', ascending=False).head(15)\n",
    "\n",
    "# Mostrar tabla y gráfico\n",
    "display(imp_df)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.barh(imp_df['Variable'], imp_df['Importancia'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 15 variables más importantes en el modelo Random Forest')\n",
    "plt.xlabel('Importancia')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
